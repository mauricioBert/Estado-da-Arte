## 🧠 Estado da Arte

A detecção de discurso de ódio em ambientes digitais tem ganhado destaque devido ao impacto das redes sociais e à necessidade de sistemas mais precisos e seguros. **Pelle e Moreira (2017)** propuseram um sistema para identificar comentários ofensivos no contexto brasileiro, destacando a importância de bases de dados anotadas e adaptadas à realidade linguística local.  
Já **Poojitha et al. (2023)** compararam modelos de **PLN** como **BERT**, **XLNet** e **CNNs**, apontando o BERT como o mais eficaz na classificação de conteúdo tóxico.  
**Pitropakis et al. (2019, 2020)** ampliaram a discussão ao relacionar PLN e **segurança em aprendizado de máquina**, criando uma taxonomia de ataques e um sistema para monitorar postagens discriminatórias.  
Por fim, **Tete (2024)** aplicou o framework **STRIDE** em **LLMs**, identificando ameaças como injeção de prompts e envenenamento de dados.  

A literatura mostra uma evolução que vai da curadoria de dados à integração de modelos avançados e segurança, apontando a necessidade de abordagens que unam **PLN** e **modelagem de ameaças**. Este trabalho busca contribuir nessa direção, propondo um sistema de detecção de discurso de ódio orientado à segurança em ambientes educacionais.

##Integrantes:
Bruno Freitas
Caio Moraes
Isabela Chaves
Mauricio Bertoldo
Ruth Mendonça
